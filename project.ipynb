{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../input/asl_alphabet_train/asl_alphabet_train'\n",
    "test_dir = '../input/asl_alphabet_test/asl_alphabet_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting one image from each class\n",
    "def load_unique():\n",
    "    size_img = 64,64 \n",
    "    images_for_plot = []\n",
    "    labels_for_plot = []\n",
    "    for folder in os.listdir(train_dir):\n",
    "        for file in os.listdir(train_dir + '/' + folder):\n",
    "            filepath = train_dir + '/' + folder + '/' + file\n",
    "            image = cv2.imread(filepath)\n",
    "            final_img = cv2.resize(image, size_img)\n",
    "            final_img = cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)\n",
    "            images_for_plot.append(final_img)\n",
    "            labels_for_plot.append(folder)\n",
    "            break\n",
    "    return images_for_plot, labels_for_plot\n",
    "\n",
    "images_for_plot, labels_for_plot = load_unique()\n",
    "print(\"unique_labels = \", labels_for_plot)\n",
    "\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "def plot_images(fig, image, label, row, col, index):\n",
    "    fig.add_subplot(row, col, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(label)\n",
    "    return\n",
    "\n",
    "image_index = 0\n",
    "row = 5\n",
    "col = 6\n",
    "for i in range(1,(row*col)):\n",
    "    plot_images(fig, images_for_plot[image_index], labels_for_plot[image_index], row, col, i)\n",
    "    image_index = image_index + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING DATA\n",
    "labels_dict = {'A':0,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,\n",
    "                   'N':13,'O':14,'P':15,'Q':16,'R':17,'S':18,'T':19,'U':20,'V':21,'W':22,'X':23,'Y':24,\n",
    "                   'Z':25,'space':26,'del':27,'nothing':28}\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads data and preprocess. Returns train and test data along with labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    size = 64,64\n",
    "    print(\"LOADING DATA FROM : \",end = \"\")\n",
    "    for folder in os.listdir(train_dir):\n",
    "        print(folder, end = ' | ')\n",
    "        for image in os.listdir(train_dir + \"/\" + folder):\n",
    "            temp_img = cv2.imread(train_dir + '/' + folder + '/' + image)\n",
    "            temp_img = cv2.resize(temp_img, size)\n",
    "            images.append(temp_img)\n",
    "            labels.append(labels_dict[folder])\n",
    "    \n",
    "    images = np.array(images)\n",
    "    images = images.astype('float32')/255.0\n",
    "    \n",
    "    labels = keras.utils.to_categorical(labels)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size = 0.05)\n",
    "    \n",
    "    print()\n",
    "    print('Loaded', len(X_train),'images for training,','Train data shape =',X_train.shape)\n",
    "    print('Loaded', len(X_test),'images for testing','Test data shape =',X_test.shape)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class distrubution\n",
    "yy = [np.argmax(i) for i in Y_train]\n",
    "plt.figure(figsize = (10,10)) # Label Count\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING MODEL\n",
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (64,64,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 29 , activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting\n",
    "model_hist = model.fit(X_train, Y_train, batch_size = 64, \n",
    "                       epochs = 15, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotting the model performance metrics to check model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_hist\n",
    "epochs = [i for i in range(15)]\n",
    "fig , ax = plt.subplots(1,2)\n",
    "train_acc = history.history['acc']\n",
    "train_loss = history.history['loss']\n",
    "val_acc = history.history['val_acc']\n",
    "val_loss = history.history['val_loss']\n",
    "fig.set_size_inches(16,9)\n",
    "\n",
    "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
    "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\n",
    "ax[0].set_title('Training & Validation Accuracy')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
    "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Testing Loss')\n",
    "ax[1].set_title('Testing Accuracy & Loss')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATING THE TRAINED MODEL ON THE TEST DATA SPLIT\n",
    "evaluate_metrics = model.evaluate(X_test, Y_test)\n",
    "print(\"\\nEvaluation Accuracy = \", \"{:.2f}%\".format(evaluate_metrics[1]*100),\n",
    "      \"\\nEvaluation loss = \" ,\"{:.6f}\".format(evaluate_metrics[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the test data Provided along with the data\n",
    "def load_test_data():\n",
    "    images = []\n",
    "    names = []\n",
    "    size = 64,64\n",
    "    for image in os.listdir(test_dir):\n",
    "        temp = cv2.imread(test_dir + '/' + image)\n",
    "        temp = cv2.resize(temp, size)\n",
    "        images.append(temp)\n",
    "        names.append(image)\n",
    "    images = np.array(images)\n",
    "    images = images.astype('float32')/255.0\n",
    "    return images, names\n",
    "\n",
    "test_images, test_img_names = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on an image and append it to the list (predictions).\n",
    "predictions = [model.predict_classes(image.reshape(1,64,64,3))[0] for image in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_for_plot(predictions):\n",
    "    predictions_labels = []\n",
    "    for i in range(len(predictions)):\n",
    "        for ins in labels_dict:\n",
    "            if predictions[i] == labels_dict[ins]:\n",
    "                predictions_labels.append(ins)\n",
    "                break\n",
    "    return predictions_labels\n",
    "\n",
    "predictions_labels_plot = get_labels_for_plot(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOTTING THE TEST DATA ALONG WITH THE PREDICTION MADE BY THE MODEL\n",
    "predfigure = plt.figure(figsize = (13,13))\n",
    "def plot_image_1(fig, image, label, prediction, predictions_label, row, col, index):\n",
    "    fig.add_subplot(row, col, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    title = \"prediction : [\" + str(predictions_label) + \"] \"+ \"\\n\" + label\n",
    "    plt.title(title)\n",
    "    return\n",
    "\n",
    "image_index = 0\n",
    "row = 5\n",
    "col = 6\n",
    "for i in range(1,(row*col-1)):\n",
    "    plot_image_1(predfigure, test_images[image_index], test_img_names[image_index], predictions[image_index], predictions_labels_plot[image_index], row, col, i)\n",
    "    image_index = image_index + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to plot confusion matrix\n",
    "def plot_confusion_matrix(y, y_pred):\n",
    "    y = np.argmax(y, axis = 1)\n",
    "    y_pred = np.argmax(y_pred, axis = 1)\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    plt.figure(figsize = (24, 20))\n",
    "    ax = plt.subplot()\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = plt.cm.Purples)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    tick_marks = np.arange(len(uniq_labels))\n",
    "    plt.xticks(tick_marks, uniq_labels, rotation=45)\n",
    "    plt.yticks(tick_marks, uniq_labels)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    ax.title.set_fontsize(20)\n",
    "    ax.xaxis.label.set_fontsize(16)\n",
    "    ax.yaxis.label.set_fontsize(16)\n",
    "    limit = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment = \"center\",color = \"white\" if cm[i, j] > limit else \"black\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "uniq_labels = sorted(os.listdir(train_dir))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "y_test_pred = model.predict(X_train, batch_size = 64, verbose = 0)\n",
    "plot_confusion_matrix(Y_train, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('asl_predictor.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#loading the saved model\n",
    "from keras.models import load_model\n",
    "# load model\n",
    "model = load_model('asl_predictor.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does prediction\n",
    "def predict(img):\n",
    "    img2 = cv2.resize(img, (64,64),interpolation = cv2.INTER_NEAREST)\n",
    "    xc = img2.reshape(-1 , 64, 64, 3)\n",
    "    predictions = model.predict(xc)    \n",
    "    label = np.argmax(predictions[0])\n",
    "    return chr(label+65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0) \n",
    "while 1:  \n",
    "  \n",
    "    ret, img = cap.read()  \n",
    "    # Display an image in a window \n",
    "    lbl = predict(img[:280 , :280 , :])\n",
    "    \n",
    "    img = cv2.rectangle(img, (0,0), (280,280), (0,0,255), 2) \n",
    "    \n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    cv2.putText(img,lbl,(450, 50),font, 1, (0, 255, 255), 2, cv2.LINE_4) \n",
    "    cv2.imshow('img',img) \n",
    "    # Wait for Esc key to stop \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: \n",
    "        break\n",
    "cap.release()\n",
    "# De-allocate any associated memory usage \n",
    "cv2.destroyAllWindows()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
